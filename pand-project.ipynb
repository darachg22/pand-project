{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2d6ce0",
   "metadata": {},
   "source": [
    "   # Pand Project Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6420185",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Iris_germanica_%28Purple_bearded_Iris%29%2C_Wakehurst_Place%2C_UK_-_Diliff.jpg/330px-Iris_germanica_%28Purple_bearded_Iris%29%2C_Wakehurst_Place%2C_UK_-_Diliff.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3d4e3",
   "metadata": {},
   "source": [
    "**Project Description**:\n",
    "\n",
    "This project concerns the well-known Fisherâ€™s Iris data set. You must research the data set\n",
    "and write documentation and code (in Python) to investigate it. An online search for\n",
    "information on the data set will convince you that many people have investigated it\n",
    "previously. You are expected to be able to break this project into several smaller tasks that\n",
    "are easier to solve, and to plug these together after they have been completed.\n",
    "\n",
    "You might do that for this project as follows:\n",
    "1. Research the data set online and write a summary about it in your README.\n",
    "2. Download the data set and add it to your repository.\n",
    "\n",
    "Write a program called analysis.py that:\n",
    "1. Outputs a summary of each variable to a single text file,\n",
    "2. Saves a histogram of each variable to png files, and\n",
    "3. Outputs a scatter plot of each pair of variables.\n",
    "4. Performs any other analysis you think is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038b443",
   "metadata": {},
   "source": [
    "**Introduction:** \n",
    "\n",
    "Fisher's Iris data set is a famous data set introduced by the British statistician and biologist Ronald Fisher in 1936. The data set consists of measurements on the length and width of sepals and petals of three varieties of iris flowers: Setosa, Versicolor, and Virginica.\n",
    "\n",
    "There are 50 samples for each species, making a total of 150 samples. The measurements are in centimeters and consist of sepal length, sepal width, petal length, and petal width.\n",
    "\n",
    "The data set is often used for statistical analysis, visualization, and machine learning algorithms, such as classification and clustering. It is also used as a benchmark data set for evaluating new methods and algorithms.\n",
    "Fisher's Iris data set is considered a classic example of exploratory data analysis and is widely used in data science education and research.\n",
    "\n",
    "References: https://www.angela1c.com/projects/iris_project/the-iris-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41280a",
   "metadata": {},
   "source": [
    "**The Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48fe44",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86abcf7",
   "metadata": {},
   "source": [
    "*Pandas* is needed in the first section which imports the data. \n",
    "\n",
    "*Mattplotlib.pyplot* is needed to import the libraries needed to create the histograms.\n",
    "\n",
    "Although I began with using the *mattplotlib.pyplot* libraries and functions, I needed to improve the clarity upon further research the *seaborn* libraries and functions improved the issues greatly.\n",
    "\n",
    "The *Os* libraries are used to create a folder that the text file will be sent to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657dceff",
   "metadata": {},
   "source": [
    "**Part One**: Outputs a summary of each variable to a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "iris_data = pd.read_csv('iris.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdfbf8",
   "metadata": {},
   "source": [
    "This section of the code imports the dataframe from a file. I had learned this code from an earlier assignment during the weekly tasks. \n",
    "\n",
    "At first I thought the best way to import the dataset was using a URL as I found the initial files I had downloaded were tempermental and difficult to get in the correct order. Then upon further research I discovered the dataframe *iris.cv* which \n",
    "I attempted to import but this would not work.I then realised, similar to an earlier task in this module, that my terminal was in the wrong location for accessing the files I need. Once this was rectified, the importing and analysing of the data file improved drastically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f67b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a summary of each variable to a single text file\n",
    "content = str(iris_data)\n",
    "print(content, file=open('variables_summary.txt', 'w'))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a33031",
   "metadata": {},
   "source": [
    "This section takes in the data and writes it to new text file within the same folder. Once again, the earlier weekly task featured this which helped me to put it together. \n",
    "\n",
    "I then faced the issue of the text file being shortened significantly. Upon invetigation, I realised the issue to be a trucance problem and found the solution here: https://nadeauinnovations.com/post/2021/05/python-tips-how-to-stop-a-pandas-data-table-from-being-truncated-when-printed/. \n",
    "\n",
    "I then added this code to rectify the issue as it extends the max columns, rows and width of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8105f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solves the trucance issue\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.width', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7090c",
   "metadata": {},
   "source": [
    "**Update:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697fbeb",
   "metadata": {},
   "source": [
    "When working on the finished project and trying to create a text file with extra added elements (see Part 4.3), I discovered the with open statement and how to open and write to a text file using them: https://www.pythonforbeginners.com/files/with-statement-in-python. I then adapted another code (referenced in Part 4.3)  to this text file (file=f). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a summary of each variable to a text file\n",
    "with open('Results/variables_summary.txt', 'w') as f:\n",
    "    print (str(iris_data), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4362c3a",
   "metadata": {},
   "source": [
    "**Part 2**: Saves a histogram of each variable to png files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c913d",
   "metadata": {},
   "source": [
    "I first created an individual histogram for each of the columns using matplot. \n",
    "\n",
    "I then updated the x and y axis and made it more readable i.e. put height along the side and width along the bottom for symmetry. \n",
    "\n",
    "After re-reading the project paramenters I realised I needed to save each histogram to a png file. I achieved this by adding the 'plot.savefig' function to each histogram.\n",
    "\n",
    "The code used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ad7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating histograms of variables\n",
    "#Sepal Length Histogram\n",
    "plt.hist(iris_data['sepal.length'], bins=7)\n",
    "plt.title('Sepal Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('sepal_length_histogram.png')\n",
    "plt.show()\n",
    "#Sepal Width\n",
    "plt.hist(iris_data['sepal.width'], bins=5)\n",
    "plt.title('Sepal Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('sepal_width_histogram.png')\n",
    "plt.show()\n",
    "#Petal Lenght\n",
    "plt.hist(iris_data['petal.length'], bins=6)\n",
    "plt.title('Petal Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('petal_length_histogram.png')\n",
    "plt.show()\n",
    "#Petal Width\n",
    "plt.hist(iris_data['petal.width'], bins=6)\n",
    "plt.title('Petal Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('petal_width_histogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b290a",
   "metadata": {},
   "source": [
    "As this is the longest section of the code I condsidered ways in which I may loop this code instead of doing each individual section. Upon research and learning I had pieced together this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in iris_data.columns[:-1]:\n",
    "    plt.hist(iris_data[col], bins=10)\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Measurement cm')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(f'{col}_histogram.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba51672",
   "metadata": {},
   "source": [
    "Here each histogram is being created and lopped, creating a shorter code. This code uses the the *for col in iris_data.columns* to take each individual column itself and loop through them, creating a histogram for each one, starting from [:-1] in the list. Their is a general bin is set to =50 in order to best include each columns data. The labels are measurement and frequency. At first I considered reverting to the original code I had created as it best explains the data being presented but instead I decided to include the meaning of each histogram in the Readme file. \n",
    "References used:\n",
    "https://stackoverflow.com/questions/62118646/i-loop-through-data-frame-graph-histogram-for-each-column-use-column-name-as-g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe10463",
   "metadata": {},
   "source": [
    "**Part Three**: Outputs a scatter plot of each pair of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbdfc4",
   "metadata": {},
   "source": [
    "Creating the scatterplots was a initially a similar task to the histogram assignment. The code looked as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cef69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scatter plot for each pair of variables\n",
    "plt.scatter(iris_data['sepal.length'], iris_data['sepal.width'])\n",
    "plt.title('Sepal Width vs Sepal Length')\n",
    "plt.xlabel('sepal.length')\n",
    "plt.ylabel('sepal.width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498d5e9",
   "metadata": {},
   "source": [
    "When the ouput of the scatterplots were created they were all the same colours and regardless of how I seemed to adjust it, it did not get more intiligable. my research led me to *Seaborn* libraries and I used these to establish a better understandable code along with a legend. I found this here: https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/. \n",
    "\n",
    "The code creates two scatterplots, with legends and saves them to the folder. The finished code for the scatterplots: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c509a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scatter plot for each pair of variables\n",
    "#Petal Width vs Petal Length\n",
    "sns.scatterplot(x='petal.length', y='petal.width',\n",
    "                hue='variety', data=iris_data, )\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2) \n",
    "plt.savefig('Scatterplot_petallength_petalwidth.png')\n",
    "plt.show()\n",
    "\n",
    "#Sepal Width vs Sepal Length\n",
    "sns.scatterplot(x='sepal.length', y='sepal.width',\n",
    "                hue='variety', data=iris_data, )\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.savefig('Scatterplot_sepallength_sepalwidth.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d6eb5",
   "metadata": {},
   "source": [
    "**Part 4**: Performs any other analysis you think is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c133c36",
   "metadata": {},
   "source": [
    "            1. Creating a pairplot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f211c26",
   "metadata": {},
   "source": [
    "When researching the task I a found a number useful analysis functions I wanted to include in this project. The first one being a pair plot, which compares the data found within the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcf42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_data.drop(['sepal.length'], axis = 1),\n",
    "             hue='variety', height=2)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.savefig('Pairplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10359379",
   "metadata": {},
   "source": [
    "This code works similarly to the scatterplot code and uses the seaborn libraries to create a mutlit dimensional map of the data. I once again used the *plt.savefig* to save the file to the directory and the *plt.legend* to create a legend for easier interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632af06",
   "metadata": {},
   "source": [
    "          2. Saving each outputted file to a new directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c6ba5",
   "metadata": {},
   "source": [
    "One of the most noticable things I discovered when creating this code was how messy it becomes when the program is ran. After I had the majority of the project completed I decided to send each png and txt output to a newly created folder. To achieve this I imported the *Os* libraries and then created the directory using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4575f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder that keeps the output files\n",
    "if not os.path.exists('Results'):\n",
    "    os.makedirs('Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932993c8",
   "metadata": {},
   "source": [
    "Following this, I needed to add 'Result/....' to the beginning of each file outputted. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d478fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content, file=open('Results/variables_summary.txt', 'w'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d1493",
   "metadata": {},
   "source": [
    "This tidied things up within the code and made access to the findings easier. It also seperates the program files from the output keeping it more organised. The skeleton of the code I used is found here: https://stackoverflow.com/questions/1274405/how-to-create-new-folder. Then in moving the file i used this code as a base: https://www.learndatasci.com/solutions/python-move-file/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865f9d9",
   "metadata": {},
   "source": [
    "        3. Text Document containing more information and analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d056ca",
   "metadata": {},
   "source": [
    "After reflecting on the code and considering ways increase the amount of useful analytics I considered ways to improve the text document outputted at the beginning of the code. I began to research ways I could improve upon the data found within and discovered codes which printed different functions such as mean, maximum and minumum value. At first I could only send this information to the terminal and began to research ways to send this a text document. \n",
    "\n",
    "References used: print statement to file: https://stackoverflow.com/questions/36571560/directing-print-output-to-a-txt-file \n",
    "Code used as skeleton for more analysis: https://www.angela1c.com/projects/iris_project/investigating-the-iris-dataset/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c841222",
   "metadata": {},
   "source": [
    "To begin this I began researching and practicing the *groupby* function of Pandas. This meant I could create extra elements to the file and use these elements to display different data surrounding the code. This also led me to see their may be a way to alter the original code that I had put together in the first section of this project (See **Update** in Part 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb12e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send print statements to the file\n",
    "    print(\"The number of observations for each variable for each Iris variety are: \\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").count(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The mean of each Iris Variety in the dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby('variety').mean(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The highest value for each Class in the Iris dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").max(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The minimum value or each Class in the Iris dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").min(), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4785c8",
   "metadata": {},
   "source": [
    "Here the referenced code above is adapted to print directly to a file with new lines being created to tidy up the data being presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f18558",
   "metadata": {},
   "source": [
    "# The Finished Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os \n",
    "# Create a folder that keeps the output files\n",
    "if not os.path.exists('Results'):\n",
    "    os.makedirs('Results')\n",
    "#importing the dataset\n",
    "iris_data = pd.read_csv('iris.csv') \n",
    "#solves the trucance issue\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.width', 999)   \n",
    "#Outputs a summary of each variable to a text file\n",
    "with open('Results/variables_summary.txt', 'w') as f:\n",
    "    print (str(iris_data), file=f)\n",
    "#Send print statements to the file\n",
    "    print(\"The number of observations for each variable for each Iris variety are: \\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").count(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The mean of each Iris Variety in the dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby('variety').mean(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The highest value for each Class in the Iris dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").max(), file=f)\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"The minimum value for each Class in the Iris dataset is: \\n\\n\", file=f)\n",
    "    print(iris_data.groupby(\"variety\").min(), file=f)\n",
    "#creating histograms of variables\n",
    "for col in iris_data.columns[:-1]:\n",
    "    plt.hist(iris_data[col], bins=50)\n",
    "    plt.title(col)\n",
    "    plt.xlabel('measurement cm')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.savefig(f'Results/{col}_histogram.png')\n",
    "    plt.show()\n",
    "#create a scatter plot for each pair of variables\n",
    "#Petal Width vs Petal Length\n",
    "sns.scatterplot(x='petal.length', y='petal.width',\n",
    "                hue='variety', data=iris_data, )\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2) \n",
    "plt.savefig('Results/Scatterplot_petallength_petalwidth.png')\n",
    "plt.show()\n",
    "#Sepal Width vs Sepal Length\n",
    "sns.scatterplot(x='sepal.length', y='sepal.width',\n",
    "                hue='variety', data=iris_data, )\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.savefig('Results/Scatterplot_sepallength_sepalwidth.png')\n",
    "plt.show()\n",
    "#Creating a Pairplot\n",
    "sns.pairplot(iris_data.drop(['sepal.length'], axis = 1),\n",
    "             hue='variety', height=2)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.savefig('Results/Pairplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6db293",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3933ce8",
   "metadata": {},
   "source": [
    "This project was an excellent learning experience for me and was of great worth in my data analytics journey. I found most elements acheivable but challenging and found the more the project progressed the more ideas I began to come with and considered more ways to make the code more neat or the output more substantial. Within the Readme file I have included how to run the code and what to expect when one does. I have also described how to interpret the data being presented. In hindsight, I believe this code could become more fluid and believe there are ways to shorten it and make it more substantial and efficient. I also believe I could have included more visualisation. These considerations I will bring forward in my journey thought programming and data analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b500b",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb53d0",
   "metadata": {},
   "source": [
    "Stack Overflow. (2016, December 29). Pandas groupby count and mean combined. Retrieved from https://stackoverflow.com/questions/41040132/pandas-groupby-count-and-mean-combined\n",
    "\n",
    "PythonForBeginners. With statement in Python. Retrieved from https://www.pythonforbeginners.com/files/with-statement-in-python\n",
    "\n",
    "Real Python.  Python Counter. Retrieved from https://realpython.com/python-counter/\n",
    "\n",
    "Stack Overflow. (2018, April 13). Pandas groupby with mean. Retrieved from https://stackoverflow.com/questions/49970309/pandas-groupby-with-mean\n",
    "\n",
    "Pythonspot.  Pandas GroupBy. Retrieved from https://pythonspot.com/pandas-groupby/\n",
    "\n",
    "Stack Overflow. (2018, February 5). Directing print output to a txt file. Retrieved from https://stackoverflow.com/questions/36571560/directing-print-output-to-a-txt-file\n",
    "\n",
    "pandas.DataFrame.to_string. pandas 1.3.0 documentation. Retrieved from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_string.html\n",
    "\n",
    "GeeksforGeeks. Exploratory Data Analysis on Iris Dataset. Retrieved from https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/\n",
    "\n",
    "Stack Overflow. (2009, August 13). How to create new folder? Retrieved from https://stackoverflow.com/questions/1274405/how-to-create-new-folder\n",
    "\n",
    "LearnDataSci. Python Move File â€“ How to Move Files and Directories in Python. Retrieved from https://www.learndatasci.com/solutions/python-move-file/\n",
    "\n",
    "Angela1C. Investigating the Iris Dataset. Retrieved from https://www.angela1c.com/projects/iris_project/investigating-the-iris-dataset/\n",
    "\n",
    "Stack Overflow. (2020, May 26). I loop through data frame, graph histogram for each column, use column name as graph title. Retrieved from https://stackoverflow.com/questions/62118646/i-loop-through-data-frame-graph-histogram-for-each-column-use-column-name-as-g\n",
    "\n",
    "Nadeau, J. (2021, May 11). Python Tips: How to Stop a Pandas Data Table from Being Truncated When Printed. Retrieved from https://nadeauinnovations.com/post/2021/05/python-tips-how-to-stop-a-pandas-data-table-from-being-truncated-when-printed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6313a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
